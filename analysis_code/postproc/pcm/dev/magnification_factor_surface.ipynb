{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca4ff21-660f-478e-800e-0245edb403cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computation of magnification factor using pycortex\n",
    "__To do :__\n",
    "- [x] adapt it to vertice analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231df2ed-083b-49eb-964c-8c42757af0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General imports\n",
    "import cortex\n",
    "import importlib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"{}/../../../utils\".format(os.getcwd()))\n",
    "from pycortex_utils import draw_cortex, set_pycortex_config_file, load_surface_pycortex, get_rois\n",
    "import nibabel as nb\n",
    "\n",
    "# Define analysis parameters\n",
    "with open('../../../settings.json') as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "tasks = analysis_info[\"task_names\"]\n",
    "task = tasks[2]\n",
    "rois = analysis_info[\"rois\"]\n",
    "vert_dist_th = analysis_info['vertex_pcm_rad']\n",
    "formats = analysis_info['formats']\n",
    "\n",
    "# debug\n",
    "formats = ['fsnative','170k']\n",
    "rois = ['V1']\n",
    "\n",
    "# Inputs\n",
    "# main_dir = '/home/mszinte/disks/meso_S/data'\n",
    "# main_dir = '/Users/uriel/disks/meso_shared/'\n",
    "main_dir = '/home/ulascombes/disks/meso_shared/'\n",
    "project_dir = 'RetinoMaps'\n",
    "subject = 'sub-01'\n",
    "deriv_fn_label = 'avg-gridfit'\n",
    "model = 'gauss'\n",
    "\n",
    "# Set pycortex db and colormaps\n",
    "cortex_dir = \"{}/{}/derivatives/pp_data/cortex\".format(main_dir, project_dir)\n",
    "set_pycortex_config_file(cortex_dir)\n",
    "importlib.reload(cortex)\n",
    "\n",
    "\n",
    "for format_, pycortex_subject in zip(formats, [subject, 'sub-170k']):\n",
    "    # define directories and fn\n",
    "    prf_dir = \"{}/{}/derivatives/pp_data/{}/{}/prf\".format(main_dir, project_dir, \n",
    "                                                           subject, format_)\n",
    "    fit_dir = \"{}/fit\".format(prf_dir)\n",
    "    prf_deriv_dir = \"{}/prf_derivatives\".format(prf_dir)\n",
    "\n",
    "    if format_ == 'fsnative':\n",
    "        atlas_name = None\n",
    "        surf_size = None\n",
    "        deriv_avg_fn_L = '{}/{}_task-{}_hemi-L_fmriprep_dct_avg_prf-deriv_{}_gridfit.func.gii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        deriv_avg_fn_R = '{}/{}_task-{}_hemi-R_fmriprep_dct_avg_prf-deriv_{}_gridfit.func.gii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        \n",
    "        results = load_surface_pycortex(L_fn=deriv_avg_fn_L, \n",
    "                                        R_fn=deriv_avg_fn_R, \n",
    "                                        return_img=True)\n",
    "\n",
    "        deriv_mat, img_L, img_R = results['data_concat'], results['img_L'], results['img_R']\n",
    "\n",
    "\n",
    "        \n",
    "    elif format_ == '170k':\n",
    "        deriv_avg_fn = '{}/{}_task-{}_fmriprep_dct_avg_prf-deriv_{}_gridfit.dtseries.nii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        atlas_name = 'mmp'\n",
    "        surf_size = '59k'\n",
    "        results = load_surface_pycortex(brain_fn=deriv_avg_fn,\n",
    "                                        return_img=True,\n",
    "                                        return_59k_mask=True, \n",
    "                                        return_170k_mask=True, \n",
    "                                        return_source_data=True)\n",
    "        deriv_mat, mask_59k, mask_170k, deriv_mat_170k, img  = results['data_concat'], results['mask_59k'], results['mask_170k'], results['source_data'], results['img']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a33902-2890-4eae-bf2d-681fdb363043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get surfaces for each hemisphere\n",
    "surfs = [cortex.polyutils.Surface(*d) for d in cortex.db.get_surf(pycortex_subject, \"flat\")]\n",
    "surf_lh, surf_rh = surfs[0], surfs[1]\n",
    "# get the vertices number per hemisphere\n",
    "lh_vert_num, rh_vert_num = surf_lh.pts.shape[0], surf_rh.pts.shape[0]\n",
    "vert_num = lh_vert_num + rh_vert_num\n",
    "\n",
    "# get a dicst with the surface vertices contained in each ROI\n",
    "# roi_verts_dict = cortex.utils.get_roi_verts(subject, mask=False)\n",
    "roi_verts_dict = get_rois(pycortex_subject, \n",
    "                          return_concat_hemis=True, \n",
    "                          rois=rois, \n",
    "                          mask=False, \n",
    "                          atlas_name=atlas_name, \n",
    "                          surf_size=surf_size)\n",
    "#### TO REPLACE BY YOUR NEW FUNCTION TO GET ROIS FROM NPZ IN CASE OF SUB-17K\n",
    "\n",
    "# derivatives settings\n",
    "rsq_idx, ecc_idx, polar_real_idx, polar_imag_idx , size_idx, \\\n",
    "    amp_idx, baseline_idx, x_idx, y_idx, hrf_1_idx, hrf_2_idx = \\\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "if model == 'gauss':\n",
    "    loo_rsq_idx = 11\n",
    "elif model == 'dn':\n",
    "    srf_amp_idx = 11\n",
    "    sff_size = 12\n",
    "    neural_baseline_idx = 13\n",
    "    surround_baseline = 14\n",
    "    loo_rsq_idx = 15\n",
    "elif model == 'css':\n",
    "    n_idx = 11\n",
    "    loo_rsq_idx = 12\n",
    "\n",
    "# parameters\n",
    "vert_rsq_data = deriv_mat[rsq_idx, ...]\n",
    "vert_x_data = deriv_mat[x_idx, ...]\n",
    "vert_y_data = deriv_mat[y_idx, ...]\n",
    "vert_size_data = deriv_mat[size_idx, ...]\n",
    "vert_ecc_data = deriv_mat[ecc_idx, ...]\n",
    "\n",
    "# create empty results\n",
    "vert_cm = np.zeros(vert_num)*np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff0d935-1770-4b51-9836-1976cf9d239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170494,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_170k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5199f3-3493-4aea-a3c1-8ea50f1d6307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI -> V1 / Hemisphere -> lh\n",
      "Vertex #42060: error: could not find suitable radius within 2 mm\n",
      "Vertex #42080: error: could not find suitable radius within 2 mm\n",
      "Vertex #43185: error: could not find suitable radius within 2 mm\n",
      "Vertex #43295: error: could not find suitable radius within 2 mm\n",
      "Vertex #43353: error: could not find suitable radius within 2 mm\n",
      "Vertex #43355: error: could not find suitable radius within 2 mm\n",
      "Vertex #43367: error: could not find suitable radius within 2 mm\n",
      "Vertex #43411: error: could not find suitable radius within 2 mm\n",
      "Vertex #43463: error: could not find suitable radius within 2 mm\n",
      "Vertex #43468: error: could not find suitable radius within 2 mm\n",
      "Vertex #43478: error: could not find suitable radius within 2 mm\n",
      "Vertex #43525: error: could not find suitable radius within 2 mm\n",
      "Vertex #43534: error: could not find suitable radius within 2 mm\n",
      "Vertex #43579: error: could not find suitable radius within 2 mm\n",
      "Vertex #43582: error: could not find suitable radius within 2 mm\n",
      "Vertex #43629: error: could not find suitable radius within 2 mm\n",
      "Vertex #43631: error: could not find suitable radius within 2 mm\n",
      "Vertex #43680: error: could not find suitable radius within 2 mm\n",
      "Vertex #43730: error: could not find suitable radius within 2 mm\n",
      "Vertex #43734: error: could not find suitable radius within 2 mm\n",
      "Vertex #43975: error: could not find suitable radius within 2 mm\n",
      "Vertex #45075: error: could not find suitable radius within 2 mm\n",
      "Vertex #45086: error: could not find suitable radius within 2 mm\n",
      "Vertex #45157: error: could not find suitable radius within 2 mm\n",
      "Vertex #45158: error: could not find suitable radius within 2 mm\n",
      "Vertex #45159: error: could not find suitable radius within 2 mm\n",
      "Vertex #45160: error: could not find suitable radius within 2 mm\n",
      "Vertex #45226: error: could not find suitable radius within 2 mm\n",
      "Vertex #45227: error: could not find suitable radius within 2 mm\n",
      "Vertex #45230: error: could not find suitable radius within 2 mm\n",
      "Vertex #45231: error: could not find suitable radius within 2 mm\n",
      "Vertex #45232: error: could not find suitable radius within 2 mm\n",
      "Vertex #45233: error: could not find suitable radius within 2 mm\n",
      "Vertex #45235: error: could not find suitable radius within 2 mm\n",
      "Vertex #45299: error: could not find suitable radius within 2 mm\n",
      "Vertex #45303: error: could not find suitable radius within 2 mm\n",
      "Vertex #45304: error: could not find suitable radius within 2 mm\n",
      "Vertex #45305: error: could not find suitable radius within 2 mm\n",
      "Vertex #45306: error: could not find suitable radius within 2 mm\n",
      "Vertex #45369: error: could not find suitable radius within 2 mm\n",
      "Vertex #45373: error: could not find suitable radius within 2 mm\n",
      "Vertex #45374: error: could not find suitable radius within 2 mm\n",
      "Vertex #45375: error: could not find suitable radius within 2 mm\n",
      "Vertex #45376: error: could not find suitable radius within 2 mm\n",
      "Vertex #45377: error: could not find suitable radius within 2 mm\n",
      "Vertex #45440: error: could not find suitable radius within 2 mm\n",
      "Vertex #45441: error: could not find suitable radius within 2 mm\n",
      "Vertex #45442: error: could not find suitable radius within 2 mm\n",
      "Vertex #45443: error: could not find suitable radius within 2 mm\n",
      "Vertex #45444: error: could not find suitable radius within 2 mm\n",
      "Vertex #45505: error: could not find suitable radius within 2 mm\n",
      "Vertex #45506: error: could not find suitable radius within 2 mm\n",
      "Vertex #45507: error: could not find suitable radius within 2 mm\n",
      "Vertex #45508: error: could not find suitable radius within 2 mm\n",
      "Vertex #45509: error: could not find suitable radius within 2 mm\n",
      "Vertex #45573: error: could not find suitable radius within 2 mm\n",
      "Vertex #45574: error: could not find suitable radius within 2 mm\n",
      "Vertex #45576: error: could not find suitable radius within 2 mm\n",
      "Vertex #45638: error: could not find suitable radius within 2 mm\n",
      "Vertex #46346: error: could not find suitable radius within 2 mm\n",
      "ROI -> V1 / Hemisphere -> rh\n",
      "Vertex #59427: error: could not find suitable radius within 2 mm\n",
      "Vertex #102539: error: could not find suitable radius within 2 mm\n",
      "Vertex #102869: error: could not find suitable radius within 2 mm\n",
      "Vertex #102877: error: could not find suitable radius within 2 mm\n",
      "Vertex #103032: error: could not find suitable radius within 2 mm\n",
      "Vertex #103127: error: could not find suitable radius within 2 mm\n",
      "Vertex #103129: error: could not find suitable radius within 2 mm\n",
      "Vertex #103354: error: could not find suitable radius within 2 mm\n",
      "Vertex #104373: error: could not find suitable radius within 2 mm\n",
      "Vertex #104447: error: could not find suitable radius within 2 mm\n",
      "Vertex #104523: error: could not find suitable radius within 2 mm\n",
      "Vertex #104581: error: could not find suitable radius within 2 mm\n",
      "Vertex #104593: error: could not find suitable radius within 2 mm\n",
      "Vertex #104602: error: could not find suitable radius within 2 mm\n",
      "Vertex #104664: error: could not find suitable radius within 2 mm\n",
      "Vertex #104729: error: could not find suitable radius within 2 mm\n",
      "Vertex #104731: error: could not find suitable radius within 2 mm\n",
      "Vertex #104732: error: could not find suitable radius within 2 mm\n",
      "Vertex #104733: error: could not find suitable radius within 2 mm\n",
      "Vertex #104739: error: could not find suitable radius within 2 mm\n",
      "Vertex #104796: error: could not find suitable radius within 2 mm\n",
      "Vertex #104797: error: could not find suitable radius within 2 mm\n",
      "Vertex #104798: error: could not find suitable radius within 2 mm\n",
      "Vertex #104799: error: could not find suitable radius within 2 mm\n",
      "Vertex #104801: error: could not find suitable radius within 2 mm\n",
      "Vertex #104802: error: could not find suitable radius within 2 mm\n",
      "Vertex #104863: error: could not find suitable radius within 2 mm\n",
      "Vertex #104864: error: could not find suitable radius within 2 mm\n",
      "Vertex #104865: error: could not find suitable radius within 2 mm\n",
      "Vertex #104866: error: could not find suitable radius within 2 mm\n",
      "Vertex #104868: error: could not find suitable radius within 2 mm\n",
      "Vertex #104987: error: could not find suitable radius within 2 mm\n",
      "Vertex #105057: error: could not find suitable radius within 2 mm\n",
      "Vertex #105106: error: could not find suitable radius within 2 mm\n",
      "Vertex #105126: error: could not find suitable radius within 2 mm\n",
      "Vertex #105178: error: could not find suitable radius within 2 mm\n",
      "Vertex #105188: error: could not find suitable radius within 2 mm\n",
      "Vertex #105363: error: could not find suitable radius within 2 mm\n",
      "Vertex #105421: error: could not find suitable radius within 2 mm\n",
      "Vertex #105461: error: could not find suitable radius within 2 mm\n",
      "Vertex #105527: error: could not find suitable radius within 2 mm\n",
      "Vertex #105548: error: could not find suitable radius within 2 mm\n",
      "Vertex #105636: error: could not find suitable radius within 2 mm\n",
      "Vertex #105637: error: could not find suitable radius within 2 mm\n",
      "Vertex #105900: error: could not find suitable radius within 2 mm\n",
      "Vertex #105911: error: could not find suitable radius within 2 mm\n",
      "Vertex #106027: error: could not find suitable radius within 2 mm\n",
      "Vertex #106073: error: could not find suitable radius within 2 mm\n",
      "Vertex #106214: error: could not find suitable radius within 2 mm\n"
     ]
    }
   ],
   "source": [
    "for roi in rois:\n",
    "    # find ROI vertex\n",
    "    roi_vert_lh_idx = roi_verts_dict[roi][roi_verts_dict[roi]<lh_vert_num]\n",
    "    roi_vert_rh_idx = roi_verts_dict[roi][roi_verts_dict[roi]>=lh_vert_num]\n",
    "    roi_surf_lh_idx = roi_vert_lh_idx\n",
    "    roi_surf_rh_idx = roi_vert_rh_idx-lh_vert_num\n",
    "\n",
    "    # get mean distance of surounding vertices included in threshold\n",
    "    vert_lh_rsq, vert_lh_size = vert_rsq_data[:lh_vert_num], vert_size_data[:lh_vert_num]\n",
    "    vert_lh_x, vert_lh_y = vert_x_data[:lh_vert_num], vert_y_data[:lh_vert_num]\n",
    "    vert_rh_rsq, vert_rh_size = vert_rsq_data[lh_vert_num:], vert_size_data[lh_vert_num:]\n",
    "    vert_rh_x, vert_rh_y = vert_x_data[lh_vert_num:], vert_y_data[lh_vert_num:]\n",
    "\n",
    "    for hemi in ['lh','rh']:\n",
    "        if hemi == 'lh':\n",
    "            surf = surf_lh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_lh_idx, roi_surf_lh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_lh_rsq, vert_lh_x, vert_lh_y, vert_lh_size\n",
    "        elif hemi == 'rh':\n",
    "            surf = surf_rh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_rh_idx, roi_surf_rh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_rh_rsq, vert_rh_x, vert_rh_y, vert_rh_size\n",
    "\n",
    "        desc = 'ROI -> {} / Hemisphere -> {}'.format(roi, hemi)\n",
    "        print(desc)\n",
    "        for i, (vert_idx, surf_idx) in enumerate(zip(roi_vert_idx, roi_surf_idx)):\n",
    "\n",
    "            if vert_rsq[surf_idx] > 0:\n",
    "\n",
    "                # get geodesic distances (mm)\n",
    "                try :\n",
    "                    geo_patch = surf.get_geodesic_patch(radius=vert_dist_th, vertex=surf_idx)\n",
    "                except Exception as e:\n",
    "                    print(\"Vertex #{}: error: {} within {} mm\".format(vert_idx, e, vert_dist_th))\n",
    "                    geo_patch['vertex_mask'] = np.zeros(surf.pts.shape[0]).astype(bool)\n",
    "                    geo_patch['geodesic_distance'] = []\n",
    "\n",
    "                vert_dist_th_idx  = geo_patch['vertex_mask']\n",
    "                vert_dist_th_dist = np.ones_like(vert_dist_th_idx)*np.nan\n",
    "                vert_dist_th_dist[vert_dist_th_idx] = geo_patch['geodesic_distance']\n",
    "\n",
    "                # exclude vextex out of roi\n",
    "                vert_dist_th_not_in_roi_idx = [idx for idx in np.where(vert_dist_th_idx)[0] if idx not in roi_surf_idx]\n",
    "                vert_dist_th_idx[vert_dist_th_not_in_roi_idx] = False\n",
    "                vert_dist_th_dist[vert_dist_th_not_in_roi_idx] = np.nan\n",
    "\n",
    "                if np.sum(vert_dist_th_idx) > 0:\n",
    "\n",
    "                    # compute average geodesic distance excluding distance to itself (see [1:])\n",
    "                    vert_geo_dist_avg = np.nanmean(vert_dist_th_dist[1:])\n",
    "\n",
    "                    # get prf parameters of vertices in geodesic distance threshold\n",
    "                    vert_ctr_x, vert_ctr_y = vert_x[surf_idx], vert_y[surf_idx]\n",
    "                    vert_dist_th_idx[surf_idx] = False\n",
    "                    vert_srd_x, vert_srd_y = np.nanmean(vert_x[vert_dist_th_idx]), np.nanmean(vert_y[vert_dist_th_idx])\n",
    "\n",
    "                    # compute prf center suround distance (deg)\n",
    "                    vert_prf_dist = np.sqrt((vert_ctr_x - vert_srd_x)**2 + (vert_ctr_y - vert_srd_y)**2)\n",
    "\n",
    "                    # compute cortical magnification in mm/deg (surface distance / pRF positon distance)\n",
    "                    vert_cm[vert_idx] = vert_geo_dist_avg/vert_prf_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee75d36-1167-4ffb-bdfb-5fcc7456e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_mat_new = np.zeros((deriv_mat.shape[0]+1, deriv_mat.shape[1]))*np.nan\n",
    "deriv_mat_new[0:-1,...] = deriv_mat\n",
    "deriv_mat_new[-1,...] = vert_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ec53d07-5c2d-4a7f-b242-21d2d9ad4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_pycortex(data, \n",
    "                        maps_names=None,\n",
    "                        img_L=None, \n",
    "                        img_R=None, \n",
    "                        lh_vert_num=None, \n",
    "                        rh_vert_num=None, \n",
    "                        img=None, \n",
    "                        brain_mask_59k=None, \n",
    "                        brain_mask_170k=None):\n",
    "    \"\"\"\n",
    "    Make a Cifti or Gifti image with data imported by PyCortex. This means that Gifti data \n",
    "    will be split by hemisphere, and Cifti data will be transformed back into 170k size.\n",
    "\n",
    "    Parameters:\n",
    "    - data: numpy array, your data.\n",
    "    - maps_names: list of strings, optional, names for the mapped data.\n",
    "    - img_L: Gifti Surface, left hemisphere surface object.\n",
    "    - img_R: Gifti Surface, right hemisphere surface object.\n",
    "    - lh_vert_num: int, number of vertices in the left hemisphere.\n",
    "    - rh_vert_num: int, number of vertices in the right hemisphere.\n",
    "    - img: Cifti Volume, source volume for mapping onto the surface.\n",
    "    - brain_mask_59k: numpy array, optional, brain mask for 59k vertices (output of the from_170k_to_59k function).\n",
    "    - brain_mask_170k: numpy array, optional, brain mask for 170k vertices (output of the from_170k_to_59k function).\n",
    "\n",
    "    Returns:\n",
    "    If mapping onto separate hemispheres (img_L and img_R provided):\n",
    "    - new_img_L: Gifti img, new surface representing data on the left hemisphere.\n",
    "    - new_img_R: Gifti img, new surface representing data on the right hemisphere.\n",
    "\n",
    "    If mapping onto a single hemisphere (img provided):\n",
    "    - new_img: Cifti img, new surface representing data on 170k size.\n",
    "    \"\"\"\n",
    "    from cifti_utils import from_59k_to_170k\n",
    "    from surface_utils import make_surface_image \n",
    "    import numpy as np\n",
    "    \n",
    "\n",
    "    if img_L and img_R: \n",
    "        data_L = data[:,:lh_vert_num]\n",
    "        data_R = data[:,-rh_vert_num:]\n",
    "\n",
    "        new_img_L = make_surface_image(data_L, img_L, maps_names=maps_names)\n",
    "        new_img_R = make_surface_image(data_R, img_R, maps_names=maps_names)\n",
    "        return new_img_L, new_img_R\n",
    "        \n",
    "    elif img:\n",
    "        data_170k = from_59k_to_170k(data_59k=data, \n",
    "                                     brain_mask_59k=brain_mask_59k, \n",
    "                                     brain_mask_170k=brain_mask_170k)\n",
    "        \n",
    "        new_img = make_surface_image(data=data, \n",
    "                                     source_img=img, \n",
    "                                     maps_names=maps_names)\n",
    "        return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52a3cc91-7278-421c-8671-0fa210492fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_59k_to_170k(data_59k, brain_mask_59k, brain_mask_170k):\n",
    "    \"\"\"\n",
    "    Transform 59k data into 170k data by filling non-59k vertices with numpy.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    data_59k : The 59k data you want to transform into 170k.\n",
    "    data_170k_orig : The original 170k data from which your 59k data originated.\n",
    "    brain_mask_59k : 59k brain mask output from from_170k_to_59k.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The transformed data in 170k format with non-59k vertices filled with numpy.nan.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # mask 59k data to optain only cortex vertex (and not medial wall vertices ) \n",
    "    data_59k = data_59k[:,brain_mask_59k]\n",
    "\n",
    "    # create an 170k full nan array\n",
    "    n_vertex_170k = brain_mask_170k.shape[0]\n",
    "    n_TRs = data_59k.shape[0]\n",
    "    data_170k_final = np.full((n_TRs,n_vertex_170k),np.nan)\n",
    "    \n",
    "    # fill the 170k array with the cortex data\n",
    "    data_170k_final[:,brain_mask_170k] = data_59k\n",
    "    \n",
    "    return data_170k_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd0e748-924d-48c9-9a87-6d28d623ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = save_surface_pycortex(data=deriv_mat_new, \n",
    "                          maps_names=None,\n",
    "                          img_L=None, \n",
    "                          img_R=None, \n",
    "                          lh_vert_num=None, \n",
    "                          rh_vert_num=None, \n",
    "                          img=img, \n",
    "                          brain_mask_59k=mask_59k, \n",
    "                          brain_mask_170k=mask_170k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa41d4b-9695-4f71-85ed-cf9c23a3da48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975ebd7-acbf-4d28-a132-c24e59ca7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rois_atlas(atlas_name, surf_size, rois=None, mask=True, path_to_atlas=None):\n",
    "    \"\"\"\n",
    "    Loads ROIs from an atlas.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    atlas_name : str\n",
    "        The name of the atlas.\n",
    "    surf_size : str\n",
    "        Size of the surface, either '59k' or '170k'.\n",
    "    rois : list of str, optional\n",
    "        List of ROIs you want to extract. If None, all ROIs are returned. \n",
    "        Default is None.\n",
    "    mask : bool, optional\n",
    "        If True, returns the ROI masks. If False, returns the indices where the masks are True.\n",
    "        Default is True.\n",
    "    path_to_atlas : str, optional\n",
    "        Path to the directory containing the atlas data. If not provided, the function looks for the atlas \n",
    "        data in the default directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rois_masks : dict\n",
    "        A dictionary where the keys represent the ROIs and the values correspond \n",
    "        to the respective masks for each hemisphere.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If 'surf_size' is not '59k' or '170k'.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    \n",
    "    # Validating surf_size\n",
    "    if surf_size not in ['59k', '170k']:\n",
    "        raise ValueError(\"Invalid value for 'surf_size'. It should be either '59k' or '170k'.\")\n",
    "        \n",
    "    # Loading data from the specified path or default directory\n",
    "    if path_to_atlas:\n",
    "        data = np.load(path_to_atlas)\n",
    "    else:    \n",
    "        atlas_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../../atlas/\"))\n",
    "        filename = \"{}_atlas_rois_{}.npz\".format(atlas_name, surf_size)\n",
    "        data = np.load('{}/{}'.format(atlas_dir, filename))\n",
    "    \n",
    "    rois_dict = dict(data)\n",
    "    \n",
    "    # Handling the case where mask is False\n",
    "    if not mask:\n",
    "        # Returning indices where the masks are True\n",
    "        rois_dict = {roi: np.where(rois_dict[roi])[0] for roi in rois_dict}\n",
    "        \n",
    "    # Filtering ROIs if rois is provided\n",
    "    if rois is None:\n",
    "        return rois_dict\n",
    "    elif isinstance(rois, list):\n",
    "        filtered_rois = {roi: rois_dict[roi] for roi in rois if roi in rois_dict}\n",
    "        return filtered_rois\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for 'rois'. It should be either None or a list of ROI names.\")\n",
    "        \n",
    "def data_from_rois(fn, subject, rois, return_concat_hemis):\n",
    "    \"\"\"\n",
    "    Load a surface, and returne vertex only data from the specified ROIs\n",
    "    ----------\n",
    "    fn : surface filename\n",
    "    subject : subject \n",
    "    rois : list of rois you want extract \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : the image load from fn   \n",
    "    data_roi : numpy rois data \n",
    "              2 dim (time x vertices from all the rois)  \n",
    "              \n",
    "    roi_idx : indices of the rois vertices \n",
    "    \n",
    "    \n",
    "    data_hemi : numpy stacked data\n",
    "                2 dim (time x vertices)    \n",
    "    \"\"\"\n",
    "    import cortex\n",
    "    from surface_utils import load_surface\n",
    "\n",
    "    # import data \n",
    "    img, data = load_surface(fn=fn)\n",
    "    len_data = data.shape[1]\n",
    "    \n",
    "    # get rois mask \n",
    "    if fn.endswith('.gii'):\n",
    "        roi_verts = cortex.get_roi_verts(subject=subject, \n",
    "                                         roi= rois, \n",
    "                                         mask=True)\n",
    "    elif fn.endswith('.nii'):\n",
    "        if len_data > 60000:\n",
    "            surf_size = '170k'\n",
    "        else:\n",
    "            surf_size = '59k'\n",
    "            \n",
    "        roi_verts = load_rois_atlas(atlas_name='mmp',surf_size=surf_size)\n",
    "    \n",
    "    na_vertices = np.isnan(data).any(axis=0)\n",
    "    \n",
    "    # create a brain mask  \n",
    "    brain_mask = np.any(list(roi_verts.values()), axis=0)\n",
    "    \n",
    "    # create a hemi mask  \n",
    "    if 'hemi-L' in fn:\n",
    "        hemi_mask = brain_mask[:len_data]\n",
    "        for i, na_vertices in enumerate(na_vertices):\n",
    "            hemi_mask[i] = not na_vertices and hemi_mask[i]\n",
    "        \n",
    "    elif 'hemi-R' in fn: \n",
    "        hemi_mask = brain_mask[-len_data:]\n",
    "        for i, na_vertices in enumerate(na_vertices):\n",
    "            hemi_mask[i] = not na_vertices and hemi_mask[i]\n",
    "    else: \n",
    "        for i, na_vertices in enumerate(na_vertices):\n",
    "            brain_mask[i] = not na_vertices and brain_mask[i]\n",
    "        \n",
    "    roi_idx = np.where(hemi_mask)[0]\n",
    "    \n",
    "    data_roi = data[:,hemi_mask]\n",
    "\n",
    "        \n",
    "    return img, data, data_roi, roi_idx\n",
    "\n",
    "def get_rois(subject, return_concat_hemis=False,rois=None, mask=True, atlas_name=None, surf_size=None):\n",
    "    \"\"\"\n",
    "    Accesses single hemisphere ROI masks for GIFTI and atlas ROI for CIFTI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject : str\n",
    "        Subject name in the pycortex database.\n",
    "    return_concat_hemis : bool, optional\n",
    "        Indicates whether to return concatenated hemisphere ROIs. Defaults to False.\n",
    "    rois : list of str, optional\n",
    "        List of ROIs you want to extract.\n",
    "    mask : bool, optional\n",
    "        Indicates whether to mask the ROIs. Defaults to True.\n",
    "    atlas_name : str, optional\n",
    "        If atlas_name is not None, subject has to be a template subject (i.e., sub-170k).\n",
    "        If provided, `surf_size` must also be specified.\n",
    "    surf_size : str, optional\n",
    "        The size in which you want the ROIs. It should be '59k' or '170k'. \n",
    "        Required if `atlas_name` is provided.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rois_masks : dict\n",
    "        A dictionary where the keys represent the ROIs and the values correspond to the respective masks for each hemisphere.\n",
    "    \"\"\"\n",
    "    import cortex\n",
    "    from surface_utils import load_surface\n",
    "    \n",
    "    surfs = [cortex.polyutils.Surface(*d) for d in cortex.db.get_surf(subject, \"flat\")]\n",
    "    surf_lh, surf_rh = surfs[0], surfs[1]\n",
    "    lh_vert_num, rh_vert_num = surf_lh.pts.shape[0], surf_rh.pts.shape[0]\n",
    "\n",
    "    \n",
    "    # get rois \n",
    "    if atlas_name :\n",
    "        roi_verts = load_rois_atlas(atlas_name=atlas_name, \n",
    "                                    surf_size=surf_size,\n",
    "                                    rois=rois, \n",
    "                                    mask=mask)\n",
    "        return roi_verts\n",
    "\n",
    "    else:\n",
    "        roi_verts = cortex.get_roi_verts(subject=subject, \n",
    "                                         roi=rois, \n",
    "                                         mask=mask)\n",
    "    \n",
    "    rois_masks_L = {roi: data[:lh_vert_num] for roi, data in roi_verts.items()}\n",
    "    rois_masks_R = {roi: data[-rh_vert_num:] for roi, data in roi_verts.items()}\n",
    "\n",
    "    if return_concat_hemis :\n",
    "        return roi_verts\n",
    "    else:\n",
    "        return rois_masks_L, rois_masks_R\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ulascombes",
   "language": "python",
   "name": "ulascombes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
